{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46da412f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 198s 1us/step\n",
      "Epoch 1/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 1.8671 - accuracy: 0.3230 - val_loss: 1.7382 - val_accuracy: 0.3729\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 1.6823 - accuracy: 0.3969 - val_loss: 1.6102 - val_accuracy: 0.4239\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 1.6074 - accuracy: 0.4254 - val_loss: 1.5943 - val_accuracy: 0.4273\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 1.5518 - accuracy: 0.4466 - val_loss: 1.5828 - val_accuracy: 0.4342\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 1.5113 - accuracy: 0.4580 - val_loss: 1.5022 - val_accuracy: 0.4632\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5022 - accuracy: 0.4632\n",
      "Base Model Results:\n",
      "\n",
      "Test Loss: 1.5022\n",
      "Test Accuracy: 46.32%\n",
      "Time Taken: 28.83 seconds\n",
      "Training with initializer: glorot_uniform\n",
      "\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8982 - accuracy: 0.3169\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7080 - accuracy: 0.3910\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6232 - accuracy: 0.4211\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5627 - accuracy: 0.4440\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5141 - accuracy: 0.4626\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.6531 - accuracy: 0.4060\n",
      "\n",
      "Test Accuracy (using 'glorot_uniform' weight initialization): 40.6%\n",
      "\n",
      "Time Taken: 23.59 seconds\n",
      "\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Training with initializer: he_normal\n",
      "\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8809 - accuracy: 0.3195\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6957 - accuracy: 0.3934\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6155 - accuracy: 0.4245\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5594 - accuracy: 0.4444\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5158 - accuracy: 0.4616\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5204 - accuracy: 0.4594\n",
      "\n",
      "Test Accuracy (using 'he_normal' weight initialization): 45.94%\n",
      "\n",
      "Time Taken: 23.23 seconds\n",
      "\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Baseline Results Comparison:\n",
      "\n",
      "Accuracy comparison:\n",
      "glorot_uniform: 1.14% accurate than base model\n",
      "he_normal: 1% accurate than base model\n",
      "\n",
      "Time comparison:\n",
      "glorot_uniform: 1.222 seconds faster than base model\n",
      "he_normal: 1.241 seconds faster than base model\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.0809 - accuracy: 0.2321\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8883 - accuracy: 0.3182\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.8080 - accuracy: 0.3488\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7573 - accuracy: 0.3706\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.7147 - accuracy: 0.3873\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6043 - accuracy: 0.4289\n",
      "\n",
      "Test Accuracy: 42.89%\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Baseline Results Comparison:\n",
      "Accuracy: 1.08% faster than base model\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 7.3634 - accuracy: 0.3119\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 4.7586 - accuracy: 0.3710\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.4053 - accuracy: 0.3855\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6800 - accuracy: 0.3970\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2892 - accuracy: 0.4011\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.1776 - accuracy: 0.3951\n",
      "\n",
      "Test Accuracy : 39.51%\n",
      "- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -\n",
      "Baseline Results Comparison:\n",
      "Accuracy: 1.17% faster than base model\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test) # Convert labels to one-hot encoding\n",
    "\n",
    "# BASE MODEL\n",
    "\n",
    "base_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "st = time.time()\n",
    "base_model_history = base_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
    "sp = time.time()\n",
    "\n",
    "print(\"- -\" * 40)\n",
    "\n",
    "base_test_loss, base_test_acc = base_model.evaluate(x_test, y_test)\n",
    "base_time_taken = round(sp-st, 2)\n",
    "print(f\"Base Model Results:\\n\\nTest Loss: {round(base_test_loss, 4)}\n",
    "\\nTest Accuracy: {round(base_test_acc * 100, 2)}%\\nTime Taken: {base_time_taken} seconds\")\n",
    "\n",
    "# # MODELS WITH KERNEL INITIALIZERS\n",
    "# Xavier & Kaiming Weight Initializers\n",
    "\n",
    "def create_model(initializer=None):\n",
    "    model_with_kernel = models.Sequential([\n",
    "        layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        layers.Dense(256, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(64, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model_with_kernel\n",
    "\n",
    "res = []\n",
    "\n",
    "# glorot_uniform - Xavier Weight Initializer, he_normal - Kaiming Weight Initializer\n",
    "weight_initializers = ['glorot_uniform', 'he_normal']\n",
    "\n",
    "for init in weight_initializers:\n",
    "    print(f\"Training with initializer: {init}\\n\")\n",
    "\n",
    "    model = create_model(initializer=init)\n",
    "    model.compile(optimizer='sgd',  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    wei_st = time.time()\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    wei_sp = time.time()\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "    time_taken = wei_sp - wei_st\n",
    "    res.append((time_taken, test_accuracy))\n",
    "\n",
    "    print(f\"\\nTest Accuracy (using '{init}' weight initialization): {round(test_accuracy * 100, 2)}\n",
    "    %\\n\\nTime Taken: {round(time_taken, 2)} seconds\\n\")\n",
    "\n",
    "    print(\"- -\" * 40)\n",
    "\n",
    "# Comparison with baseline results\n",
    "base_glorot_acc = round(base_test_acc / res[0][1], 2)\n",
    "base_glorot_time = round(base_time_taken / res[0][0], 3)\n",
    "base_he_acc = round(base_test_acc / res[1][1])\n",
    "base_he_time = round(base_time_taken / res[1][0], 3)\n",
    "\n",
    "print(f\"Baseline Results Comparison:\\n\\nAccuracy comparison:\\n{weight_initializers[0]}: {base_glorot_acc}% accurate than base model\\n\n",
    "{weight_initializers[1]}: {base_he_acc}% accurate than base model\")\n",
    "print(f\"\\nTime comparison:\\n{weight_initializers[0]}: {base_glorot_time} seconds faster than base model\\n\n",
    "{weight_initializers[1]}: {base_he_time} seconds faster than base model\")\n",
    "\n",
    "\n",
    "# # MODEL WITH DROPOUT LAYER\n",
    "# Dropout Rate - 0.2\n",
    "\n",
    "model_with_dropout = models.Sequential([\n",
    "      layers.Flatten(input_shape=(32, 32, 3)),\n",
    "      layers.Dense(256, activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "# Load and preprocess CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "model_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_with_dropout.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "dropout_test_loss, dropout_test_accuracy = model_with_dropout.evaluate(x_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {round(dropout_test_accuracy * 100, 4)}%\")\n",
    "\n",
    "print(\"- -\" * 40)\n",
    "\n",
    "# Comparison with baseline results\n",
    "base_dropout_acc = round(base_test_acc / dropout_test_accuracy , 2)\n",
    "\n",
    "print(f\"Baseline Results Comparison:\\nAccuracy: {base_dropout_acc}% faster than base model\")\n",
    "\n",
    "\n",
    "# # MODEL WITH KERNEL REGULARIZER\n",
    "# L2 Kernel Regularizer\n",
    "\n",
    "model_with_reg = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model_with_reg.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_with_reg.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "reg_test_loss, reg_test_accuracy = model_with_reg.evaluate(x_test, y_test)\n",
    "print(f\"\\nTest Accuracy : {round(reg_test_accuracy * 100, 4)}%\")\n",
    "\n",
    "print(\"- -\" * 40)\n",
    "\n",
    "# Comparison with baseline results\n",
    "base_reg_acc = round(base_test_acc / reg_test_accuracy , 2)\n",
    "\n",
    "print(f\"Baseline Results Comparison:\\nAccuracy: {base_reg_acc}% faster than base model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6b44a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
